{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_csv(\"data/new_sentence_df_0509.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuples</th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relation</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>merger_or_acq</th>\n",
       "      <th>keywords</th>\n",
       "      <th>mentions</th>\n",
       "      <th>relations</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>...</th>\n",
       "      <th>final_company_deal</th>\n",
       "      <th>general_questions</th>\n",
       "      <th>head_questions</th>\n",
       "      <th>tail_questions</th>\n",
       "      <th>new_general_questions</th>\n",
       "      <th>new_head_questions</th>\n",
       "      <th>new_tail_questions</th>\n",
       "      <th>latest_general_questions</th>\n",
       "      <th>latest_head_questions</th>\n",
       "      <th>latest_tail_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('apple_inc.', 'considering_acq', 'netflix', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>There is a 40% likelihood that Apple will acqu...</td>\n",
       "      <td>considering_acq</td>\n",
       "      <td>2018-01-01 09:04:47</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Citi', 'Org'), ('Apple', 'Bidder'), ('Netfl...</td>\n",
       "      <td>['40% likelihood']</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>apple_inc._netflix</td>\n",
       "      <td>((\"What's the deal between apple_inc. and netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"What's the deal between apple_inc. and netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('prestige_group', 'success_acq', 'capitaland'...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NEW DELHI: Realty firm Prestige group today sa...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2018-01-01 12:46:26</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Prestige group', 'Bidder'), ('it will acqui...</td>\n",
       "      <td>['it will acquire']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>prestige_group_capitaland</td>\n",
       "      <td>((\"What's the deal between prestige_group and ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between prestige_group and ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('bd_(company)', 'success_acq', 'bard', '2018-...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Under the terms of the transaction, upon compl...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>[('Bard', 'Target'), ('Bard', 'Target'), ('BD'...</td>\n",
       "      <td>['upon completion of the acquisition']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>bd_(company)_bard</td>\n",
       "      <td>((\"What's the deal between bd_(company) and ba...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between bd_(company) and ba...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('bhi', 'success_merger', 'marcventure', '2018...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Marcventure said the merger with BHI will enab...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2018-01-02 09:09:57</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('BHI', 'Bidder'), ('Marcventure', 'Bidder'),...</td>\n",
       "      <td>['merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>bhi_marcventure</td>\n",
       "      <td>((\"What's the deal between bhi and marcventure...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between bhi and marcventure...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('h.j. heinz', 'success_merger', 'kraft_foods'...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>For two years, investors and other stakeholder...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2018-01-02 10:15:00</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('Kraft Heinz', 'Org'), ('H.J. Heinz', 'Bidde...</td>\n",
       "      <td>['created through the $46 billion merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>h.j. heinz_kraft_foods</td>\n",
       "      <td>((\"What's the deal between h.j. heinz and kraf...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "      <td>[(\"What's the deal between h.j. heinz and kraf...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tuples  article_id  \\\n",
       "0  ('apple_inc.', 'considering_acq', 'netflix', '...         1.0   \n",
       "1  ('prestige_group', 'success_acq', 'capitaland'...         2.0   \n",
       "2  ('bd_(company)', 'success_acq', 'bard', '2018-...         5.0   \n",
       "3  ('bhi', 'success_merger', 'marcventure', '2018...        19.0   \n",
       "4  ('h.j. heinz', 'success_merger', 'kraft_foods'...        22.0   \n",
       "\n",
       "                                           sentences         relation  \\\n",
       "0  There is a 40% likelihood that Apple will acqu...  considering_acq   \n",
       "1  NEW DELHI: Realty firm Prestige group today sa...      success_acq   \n",
       "2  Under the terms of the transaction, upon compl...      success_acq   \n",
       "3  Marcventure said the merger with BHI will enab...   success_merger   \n",
       "4  For two years, investors and other stakeholder...   success_merger   \n",
       "\n",
       "           publishedAt merger_or_acq     keywords  \\\n",
       "0  2018-01-01 09:04:47           Acq      acquire   \n",
       "1  2018-01-01 12:46:26           Acq      acquire   \n",
       "2  2018-01-02 00:00:00           Acq  acquisition   \n",
       "3  2018-01-02 09:09:57        Merger       merger   \n",
       "4  2018-01-02 10:15:00        Merger       merger   \n",
       "\n",
       "                                            mentions  \\\n",
       "0  [('Citi', 'Org'), ('Apple', 'Bidder'), ('Netfl...   \n",
       "1  [('Prestige group', 'Bidder'), ('it will acqui...   \n",
       "2  [('Bard', 'Target'), ('Bard', 'Target'), ('BD'...   \n",
       "3  [('BHI', 'Bidder'), ('Marcventure', 'Bidder'),...   \n",
       "4  [('Kraft Heinz', 'Org'), ('H.J. Heinz', 'Bidde...   \n",
       "\n",
       "                                    relations  wikidata  ...  \\\n",
       "0                          ['40% likelihood']      True  ...   \n",
       "1                         ['it will acquire']     False  ...   \n",
       "2      ['upon completion of the acquisition']     False  ...   \n",
       "3                                  ['merger']     False  ...   \n",
       "4  ['created through the $46 billion merger']     False  ...   \n",
       "\n",
       "          final_company_deal  \\\n",
       "0         apple_inc._netflix   \n",
       "1  prestige_group_capitaland   \n",
       "2          bd_(company)_bard   \n",
       "3            bhi_marcventure   \n",
       "4     h.j. heinz_kraft_foods   \n",
       "\n",
       "                                   general_questions  \\\n",
       "0  ((\"What's the deal between apple_inc. and netf...   \n",
       "1  ((\"What's the deal between prestige_group and ...   \n",
       "2  ((\"What's the deal between bd_(company) and ba...   \n",
       "3  ((\"What's the deal between bhi and marcventure...   \n",
       "4  ((\"What's the deal between h.j. heinz and kraf...   \n",
       "\n",
       "                                      head_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2  {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4                        {'before': [], 'after': []}   \n",
       "\n",
       "                                      tail_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2                        {'before': [], 'after': []}   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4  {'before': [('Who owns Kool-Aid (Q1531983) bef...   \n",
       "\n",
       "                               new_general_questions  \\\n",
       "0  [(\"What's the deal between apple_inc. and netf...   \n",
       "1  [(\"What's the deal between prestige_group and ...   \n",
       "2  [(\"What's the deal between bd_(company) and ba...   \n",
       "3  [(\"What's the deal between bhi and marcventure...   \n",
       "4  [(\"What's the deal between h.j. heinz and kraf...   \n",
       "\n",
       "                                  new_head_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2  {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4                        {'before': [], 'after': []}   \n",
       "\n",
       "                                  new_tail_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2                        {'before': [], 'after': []}   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4  {'before': [('Who owns Kool-Aid (Q1531983) bef...   \n",
       "\n",
       "                            latest_general_questions  \\\n",
       "0  [(\"Who's the bidder of the acquisition deal on...   \n",
       "1  [(\"Who's the bidder of the acquisition deal on...   \n",
       "2  [(\"Who's the bidder of the acquisition deal on...   \n",
       "3  [(\"Who's the first bidder of the merger deal o...   \n",
       "4  [(\"Who's the first bidder of the merger deal o...   \n",
       "\n",
       "                               latest_head_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2  {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4                        {'before': [], 'after': []}   \n",
       "\n",
       "                               latest_tail_questions  \n",
       "0                                                NaN  \n",
       "1                        {'before': [], 'after': []}  \n",
       "2                        {'before': [], 'after': []}  \n",
       "3                        {'before': [], 'after': []}  \n",
       "4  {'before': [('Who owns Kool-Aid (Q1531983) bef...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tuples', 'article_id', 'sentences', 'relation', 'publishedAt',\n",
       "       'merger_or_acq', 'keywords', 'mentions', 'relations', 'wikidata',\n",
       "       'lowered_head', 'lowered_tail', 'companies_deal', 'final_company_deal',\n",
       "       'general_questions', 'head_questions', 'tail_questions',\n",
       "       'new_general_questions', 'new_head_questions', 'new_tail_questions',\n",
       "       'latest_general_questions', 'latest_head_questions',\n",
       "       'latest_tail_questions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_head_questions       42.177941\n",
      "head_questions              42.177941\n",
      "tail_questions              42.177941\n",
      "latest_tail_questions       42.177941\n",
      "new_tail_questions          42.177941\n",
      "new_head_questions          42.177941\n",
      "tuples                       0.000000\n",
      "keywords                     0.000000\n",
      "merger_or_acq                0.000000\n",
      "publishedAt                  0.000000\n",
      "relation                     0.000000\n",
      "sentences                    0.000000\n",
      "article_id                   0.000000\n",
      "mentions                     0.000000\n",
      "relations                    0.000000\n",
      "general_questions            0.000000\n",
      "final_company_deal           0.000000\n",
      "companies_deal               0.000000\n",
      "lowered_tail                 0.000000\n",
      "lowered_head                 0.000000\n",
      "wikidata                     0.000000\n",
      "new_general_questions        0.000000\n",
      "latest_general_questions     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check null: tuples, general_questions, new_general_questions, latest_general_questions are all available\n",
    "null_percent = qa.isnull().mean().sort_values(ascending=False) * 100\n",
    "print(null_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "qa[\"general_questions\"] = qa[\"general_questions\"].apply(ast.literal_eval)\n",
    "qa[\"new_general_questions\"] = qa[\"new_general_questions\"].apply(ast.literal_eval)\n",
    "qa[\"latest_general_questions\"] = qa[\"latest_general_questions\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5721\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(qa[\"general_questions\"])\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m average_lengths \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m: qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[43mnum_rows\u001b[49m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m: qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mnum_rows,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m: qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mnum_rows,\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of questions: \u001b[39m\u001b[38;5;124m\"\u001b[39m, average_lengths)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_rows' is not defined"
     ]
    }
   ],
   "source": [
    "average_lengths = {\n",
    "    \"general_questions\": qa[\"general_questions\"].apply(len).sum()/num_rows,\n",
    "    \"new_general_questions\": qa[\"new_general_questions\"].apply(len).sum()/num_rows,\n",
    "    \"latest_general_questions\": qa[\"latest_general_questions\"].apply(len).sum()/num_rows,\n",
    "}\n",
    "print(f\"number of questions: \", average_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"What's the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'Acquisition'), (\"Who's the bidder of the acquisition deal on 2018-01-01 09:04:47?\", 'apple_inc.'), (\"Who's the target of the acquisition deal on 2018-01-01 09:04:47?\", 'netflix'), (\"What's the status of the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'considering'))\n",
      "[(\"What's the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'Acquisition', 'entity'), (\"Who's the bidder of the acquisition deal on 2018-01-01 09:04:47?\", 'apple_inc.', 'entity'), (\"Who's the target of the acquisition deal on 2018-01-01 09:04:47?\", 'netflix', 'entity'), (\"What's the status of the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'considering', 'entity')]\n",
      "[(\"Who's the bidder of the acquisition deal on 2018-01-01 09:04:47?\", 'apple_inc.', 'entity'), (\"Who's the target of the acquisition deal on 2018-01-01 09:04:47?\", 'netflix', 'entity'), (\"What's the status of the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'considering_acq', 'relation')]\n"
     ]
    }
   ],
   "source": [
    "first_q = qa[\"general_questions\"][0]\n",
    "print(first_q)\n",
    "first_new_q = qa[\"new_general_questions\"][0]\n",
    "print(first_new_q)\n",
    "first_latest_q = qa[\"latest_general_questions\"][0]\n",
    "print(first_latest_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')\n"
     ]
    }
   ],
   "source": [
    "first_tuple = qa[\"tuples\"][0]\n",
    "print(first_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')\n"
     ]
    }
   ],
   "source": [
    "# prepare contexts\n",
    "qa[\"tuples\"] = qa[\"tuples\"].apply(ast.literal_eval)\n",
    "print(qa[\"tuples\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(qa[\"tuples\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build context\n",
    "def transform_relation(rel):\n",
    "    if rel.endswith(\"ing_acq\"):\n",
    "        prefix = rel.replace(\"_acq\", \"\").replace(\"_\", \" \")\n",
    "        return f\"is {prefix} the acquisition of\"\n",
    "    elif rel.endswith(\"ed_acq\"):\n",
    "        prefix = rel.replace(\"_acq\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has {prefix} the acquisition of\"\n",
    "    elif rel.endswith(\"_acq\"):\n",
    "        prefix = rel.replace(\"_acq\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has achieved {prefix} of the acquisition of\"\n",
    "    elif rel.endswith(\"ing_merger\"):\n",
    "        prefix = rel.replace(\"_merger\", \"\").replace(\"_\", \" \")\n",
    "        return f\"is {prefix} the merger of\"\n",
    "    elif rel.endswith(\"ed_merger\"):\n",
    "        prefix = rel.replace(\"_merger\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has {prefix} the merger of\"\n",
    "    elif rel.endswith(\"_merger\"):\n",
    "        prefix = rel.replace(\"_merger\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has achieved {prefix} of the merger of\"\n",
    "    else:\n",
    "        return rel.replace(\"_\", \" \")  # fallback: simple spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format full context string\n",
    "def format_context(tup):\n",
    "    e1, rel, e2, time = tup\n",
    "    relation_phrase = transform_relation(rel)\n",
    "    date = time.split(\" \")[0]\n",
    "    return f\"{e1} {relation_phrase} {e2} on {date}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa[\"contexts\"] = qa[\"tuples\"].apply(format_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_(company) has achieved success of the acquisition of munster on 2019-01-10.\n"
     ]
    }
   ],
   "source": [
    "print(qa[\"contexts\"][2319])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (What's the deal between apple_inc. and netfli...\n",
      "1    (Who's the bidder of the acquisition deal on 2...\n",
      "2    (Who's the target of the acquisition deal on 2...\n",
      "3    (What's the status of the deal between apple_i...\n",
      "Name: question_and_answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Explode the 'general_questions' list into separate rows\n",
    "qa_expanded = qa.explode(\"general_questions\", ignore_index=True)\n",
    "\n",
    "qa_expanded = qa_expanded.rename(columns={\"general_questions\": \"question_and_answer\"})\n",
    "\n",
    "print(qa_expanded[qa_expanded[\"tuples\"]==('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')][\"question_and_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_expanded[[\"question\", \"answer\"]] = pd.DataFrame(qa_expanded[\"question_and_answer\"].tolist(), index=qa_expanded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    What's the deal between apple_inc. and netflix...\n",
      "1    Who's the bidder of the acquisition deal on 20...\n",
      "2    Who's the target of the acquisition deal on 20...\n",
      "3    What's the status of the deal between apple_in...\n",
      "Name: question, dtype: object\n",
      "0    Acquisition\n",
      "1     apple_inc.\n",
      "2        netflix\n",
      "3    considering\n",
      "Name: answer, dtype: object\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(qa_expanded[qa_expanded[\"tuples\"]==('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')][\"question\"])\n",
    "print(qa_expanded[qa_expanded[\"tuples\"]==('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')][\"answer\"])\n",
    "print(type(qa_expanded[\"answer\"][0]))\n",
    "print(type(qa_expanded[\"question\"][0]))\n",
    "print(type(qa_expanded[\"contexts\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_start_char(row):\n",
    "    try:\n",
    "        contexts_lower = row[\"contexts\"].lower()\n",
    "        answer_lower = row[\"answer\"].lower()\n",
    "        return contexts_lower.index(answer_lower)\n",
    "    except ValueError:\n",
    "        return -1  # if answer not found\n",
    "\n",
    "# Apply this to your DataFrame\n",
    "qa_expanded[\"start_char\"] = qa_expanded.apply(compute_start_char, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    30\n",
      "1     0\n",
      "2    45\n",
      "3    14\n",
      "4    43\n",
      "5     0\n",
      "6    58\n",
      "7    28\n",
      "8    41\n",
      "9     0\n",
      "Name: start_char, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(qa_expanded[\"start_char\"][:10])\n",
    "print((qa_expanded[\"start_char\"]==-1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ys298/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def prepare_batch(batch_df):\n",
    "    questions = batch_df[\"question\"].tolist()\n",
    "    contexts = batch_df[\"contexts\"].tolist()\n",
    "    answers = batch_df[\"answer\"].tolist()\n",
    "    start_chars = batch_df[\"start_char\"].tolist()\n",
    "\n",
    "    # Tokenize as a batch\n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Align each answer to token-level positions\n",
    "    for i in range(len(questions)):\n",
    "        offsets = encodings[\"offset_mapping\"][i]\n",
    "        start_char = int(start_chars[i])\n",
    "        end_char = start_char + len(str(answers[i]))\n",
    "\n",
    "        start_token = end_token = 0\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "\n",
    "        start_positions.append(start_token)\n",
    "        end_positions.append(end_token)\n",
    "\n",
    "    # Add start/end positions\n",
    "    encodings[\"start_positions\"] = torch.tensor(start_positions)\n",
    "    encodings[\"end_positions\"] = torch.tensor(end_positions)\n",
    "\n",
    "    # Remove offset mapping (no longer needed)\n",
    "    encodings.pop(\"offset_mapping\")\n",
    "\n",
    "    return encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(qa_expanded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_train = prepare_batch(train_df)\n",
    "encodings_test = prepare_batch(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export encodings\n",
    "torch.save(dict(encodings_train), \"encodings_train_dict.pt\")\n",
    "torch.save(dict(encodings_test), \"encodings_test_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try loading\n",
    "encodings_train = torch.load(\"encodings_train_dict.pt\")\n",
    "encodings_test = torch.load(\"encodings_test_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ys298/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-03-24 21:08:30.929988: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-24 21:08:31.791920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-03-24 21:08:31.792098: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-03-24 21:08:31.920784: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-24 21:08:32.193921: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-03-24 21:08:34.617228: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "finished loading data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting training...\n",
      "[Epoch 1] Loss: 3.3024 | Accuracy so far: 0.0481\n",
      "[Epoch 1] Loss: 2.0561 | Accuracy so far: 0.1200\n",
      "[Epoch 1] Loss: 1.5781 | Accuracy so far: 0.2204\n",
      "[Epoch 1] Loss: 0.8496 | Accuracy so far: 0.2675\n",
      "[Epoch 1] Loss: 0.8138 | Accuracy so far: 0.3214\n",
      "[Epoch 1] Loss: 0.5714 | Accuracy so far: 0.3733\n",
      "[Epoch 1] Loss: 0.3433 | Accuracy so far: 0.4332\n",
      "[Epoch 1] Loss: 0.3140 | Accuracy so far: 0.4850\n",
      "[Epoch 1] Loss: 0.2906 | Accuracy so far: 0.5321\n",
      "[Epoch 1] Loss: 0.0754 | Accuracy so far: 0.5720\n",
      "[Epoch 1] Loss: 0.0915 | Accuracy so far: 0.6014\n",
      "[Epoch 1] Loss: 0.0538 | Accuracy so far: 0.6317\n",
      "[Epoch 1] Loss: 0.0569 | Accuracy so far: 0.6603\n",
      "[Epoch 1] Loss: 0.0320 | Accuracy so far: 0.6821\n",
      "[Epoch 1] Loss: 0.0428 | Accuracy so far: 0.7035\n",
      "[Epoch 1] Loss: 0.0075 | Accuracy so far: 0.7212\n",
      "[Epoch 1] Loss: 0.0187 | Accuracy so far: 0.7383\n",
      "[Epoch 1] Loss: 0.0120 | Accuracy so far: 0.7522\n",
      "[Epoch 1] Loss: 0.0081 | Accuracy so far: 0.7658\n",
      "[Epoch 1] Loss: 0.0072 | Accuracy so far: 0.7765\n",
      "[Epoch 1] Loss: 0.0161 | Accuracy so far: 0.7875\n",
      "[Epoch 1] Loss: 0.1745 | Accuracy so far: 0.7964\n",
      "[Epoch 1] Loss: 0.0298 | Accuracy so far: 0.8043\n",
      "[Epoch 1] Loss: 0.0261 | Accuracy so far: 0.8108\n",
      "[Epoch 1] Loss: 0.0052 | Accuracy so far: 0.8187\n",
      "[Epoch 1] Loss: 0.0056 | Accuracy so far: 0.8246\n",
      "[Epoch 1] Loss: 0.0653 | Accuracy so far: 0.8314\n",
      "[Epoch 1] Loss: 0.0044 | Accuracy so far: 0.8371\n",
      "[Epoch 1] Loss: 0.0065 | Accuracy so far: 0.8430\n",
      "[Epoch 1] Loss: 0.0284 | Accuracy so far: 0.8480\n",
      "[Epoch 1] Loss: 0.0160 | Accuracy so far: 0.8531\n",
      "[Epoch 1] Loss: 0.0037 | Accuracy so far: 0.8575\n",
      "[Epoch 1] Loss: 0.0044 | Accuracy so far: 0.8617\n",
      "[Epoch 1] Loss: 0.0029 | Accuracy so far: 0.8656\n",
      "[Epoch 1] Loss: 0.0027 | Accuracy so far: 0.8696\n",
      "[Epoch 1] Loss: 0.0024 | Accuracy so far: 0.8731\n",
      "[Epoch 1] Loss: 0.0060 | Accuracy so far: 0.8763\n",
      "[Epoch 1] Loss: 0.0040 | Accuracy so far: 0.8792\n",
      "[Epoch 1] Loss: 0.0086 | Accuracy so far: 0.8824\n",
      "[Epoch 1] Loss: 0.0042 | Accuracy so far: 0.8852\n",
      "[Epoch 1] Loss: 0.0030 | Accuracy so far: 0.8882\n",
      "[Epoch 1] Loss: 0.0028 | Accuracy so far: 0.8905\n",
      "[Epoch 1] Loss: 0.0083 | Accuracy so far: 0.8931\n",
      "[Epoch 1] Loss: 0.0039 | Accuracy so far: 0.8955\n",
      "[Epoch 1] Loss: 0.0025 | Accuracy so far: 0.8979\n",
      "[Epoch 1] Loss: 0.0020 | Accuracy so far: 0.9000\n",
      "[Epoch 1] Loss: 0.0021 | Accuracy so far: 0.9022\n",
      "[Epoch 1] Loss: 0.0100 | Accuracy so far: 0.9042\n",
      "[Epoch 1] Loss: 0.0774 | Accuracy so far: 0.9058\n",
      "[Epoch 1] Loss: 0.0075 | Accuracy so far: 0.9074\n",
      "[Epoch 1] Loss: 0.0037 | Accuracy so far: 0.9093\n",
      "[Epoch 1] Loss: 0.0052 | Accuracy so far: 0.9110\n",
      "[Epoch 1] Loss: 0.0025 | Accuracy so far: 0.9127\n",
      "[Epoch 1] Loss: 0.0055 | Accuracy so far: 0.9141\n",
      "[Epoch 1] Loss: 0.0019 | Accuracy so far: 0.9157\n",
      "[Epoch 1] Loss: 0.0165 | Accuracy so far: 0.9171\n",
      "[Epoch 1] Loss: 0.0077 | Accuracy so far: 0.9187\n",
      "[Epoch 1] Loss: 0.0081 | Accuracy so far: 0.9198\n",
      "[Epoch 1] Loss: 0.0033 | Accuracy so far: 0.9211\n",
      "[Epoch 1] Loss: 0.0069 | Accuracy so far: 0.9223\n",
      "[Epoch 1] Loss: 0.0135 | Accuracy so far: 0.9235\n",
      "[Epoch 1] Loss: 0.0079 | Accuracy so far: 0.9247\n",
      "[Epoch 1] Loss: 0.0022 | Accuracy so far: 0.9259\n",
      "[Epoch 1] Loss: 0.0016 | Accuracy so far: 0.9270\n",
      "[Epoch 1] Loss: 0.0014 | Accuracy so far: 0.9282\n",
      "[Epoch 1] Loss: 0.0013 | Accuracy so far: 0.9292\n",
      "[Epoch 1] Loss: 0.0015 | Accuracy so far: 0.9303\n",
      "[Epoch 1] Loss: 0.0031 | Accuracy so far: 0.9312\n",
      "[Epoch 1] Loss: 0.0241 | Accuracy so far: 0.9322\n",
      "[Epoch 1] Loss: 0.0020 | Accuracy so far: 0.9331\n",
      "[Epoch 1] Loss: 0.0149 | Accuracy so far: 0.9340\n",
      "[Epoch 1] Loss: 0.0032 | Accuracy so far: 0.9346\n",
      "[Epoch 1] Loss: 0.0517 | Accuracy so far: 0.9355\n",
      "[Epoch 1] Loss: 0.0030 | Accuracy so far: 0.9364\n",
      "[Epoch 1] Loss: 0.0014 | Accuracy so far: 0.9372\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9380\n",
      "[Epoch 1] Loss: 0.0015 | Accuracy so far: 0.9389\n",
      "[Epoch 1] Loss: 0.0024 | Accuracy so far: 0.9395\n",
      "[Epoch 1] Loss: 0.0063 | Accuracy so far: 0.9403\n",
      "[Epoch 1] Loss: 0.0091 | Accuracy so far: 0.9410\n",
      "[Epoch 1] Loss: 0.0382 | Accuracy so far: 0.9418\n",
      "[Epoch 1] Loss: 0.0019 | Accuracy so far: 0.9424\n",
      "[Epoch 1] Loss: 0.0021 | Accuracy so far: 0.9432\n",
      "[Epoch 1] Loss: 0.0017 | Accuracy so far: 0.9438\n",
      "[Epoch 1] Loss: 0.0024 | Accuracy so far: 0.9444\n",
      "[Epoch 1] Loss: 0.0012 | Accuracy so far: 0.9450\n",
      "[Epoch 1] Loss: 0.0015 | Accuracy so far: 0.9457\n",
      "[Epoch 1] Loss: 0.0014 | Accuracy so far: 0.9463\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9469\n",
      "[Epoch 1] Loss: 0.0016 | Accuracy so far: 0.9474\n",
      "[Epoch 1] Loss: 0.0054 | Accuracy so far: 0.9479\n",
      "[Epoch 1] Loss: 0.0027 | Accuracy so far: 0.9485\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9491\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9496\n",
      "[Epoch 1] Loss: 0.0012 | Accuracy so far: 0.9501\n",
      "[Epoch 1] Loss: 0.0131 | Accuracy so far: 0.9503\n",
      "[Epoch 1] Loss: 0.0093 | Accuracy so far: 0.9508\n",
      "[Epoch 1] Loss: 0.0044 | Accuracy so far: 0.9513\n",
      "[Epoch 1] Loss: 0.0055 | Accuracy so far: 0.9518\n",
      "[Epoch 1] Loss: 0.0013 | Accuracy so far: 0.9523\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9528\n",
      "[Epoch 1] Loss: 0.0018 | Accuracy so far: 0.9532\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9537\n",
      "[Epoch 1] Loss: 0.0012 | Accuracy so far: 0.9541\n",
      "[Epoch 1] Loss: 0.0019 | Accuracy so far: 0.9544\n",
      "[Epoch 1] Loss: 0.0134 | Accuracy so far: 0.9548\n",
      "[Epoch 1] Loss: 0.0035 | Accuracy so far: 0.9552\n",
      "[Epoch 1] Loss: 0.0018 | Accuracy so far: 0.9556\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9560\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9564\n",
      "[Epoch 1] Loss: 0.0015 | Accuracy so far: 0.9568\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9571\n",
      "[Epoch 1] Loss: 0.0048 | Accuracy so far: 0.9574\n",
      "[Epoch 1] Loss: 0.0082 | Accuracy so far: 0.9578\n",
      "[Epoch 1] Loss: 0.0170 | Accuracy so far: 0.9582\n",
      "[Epoch 1] Loss: 0.0032 | Accuracy so far: 0.9585\n",
      "[Epoch 1] Loss: 0.0478 | Accuracy so far: 0.9587\n",
      "[Epoch 1] Loss: 0.0013 | Accuracy so far: 0.9591\n",
      "[Epoch 1] Loss: 0.0012 | Accuracy so far: 0.9594\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9597\n",
      "[Epoch 1] Loss: 0.6059 | Accuracy so far: 0.9600\n",
      "[Epoch 1] Loss: 0.8387 | Accuracy so far: 0.9602\n",
      "[Epoch 1] Loss: 0.0034 | Accuracy so far: 0.9603\n",
      "[Epoch 1] Loss: 0.4684 | Accuracy so far: 0.9606\n",
      "[Epoch 1] Loss: 0.0019 | Accuracy so far: 0.9609\n",
      "[Epoch 1] Loss: 0.0017 | Accuracy so far: 0.9611\n",
      "[Epoch 1] Loss: 0.0296 | Accuracy so far: 0.9614\n",
      "[Epoch 1] Loss: 0.0149 | Accuracy so far: 0.9616\n",
      "[Epoch 1] Loss: 0.0015 | Accuracy so far: 0.9619\n",
      "[Epoch 1] Loss: 0.0084 | Accuracy so far: 0.9622\n",
      "[Epoch 1] Loss: 0.0016 | Accuracy so far: 0.9624\n",
      "[Epoch 1] Loss: 0.0021 | Accuracy so far: 0.9626\n",
      "[Epoch 1] Loss: 0.0035 | Accuracy so far: 0.9629\n",
      "[Epoch 1] Loss: 0.0014 | Accuracy so far: 0.9631\n",
      "[Epoch 1] Loss: 0.0159 | Accuracy so far: 0.9633\n",
      "[Epoch 1] Loss: 0.0148 | Accuracy so far: 0.9635\n",
      "[Epoch 1] Loss: 0.0082 | Accuracy so far: 0.9638\n",
      "[Epoch 1] Loss: 0.0007 | Accuracy so far: 0.9641\n",
      "[Epoch 1] Loss: 0.0018 | Accuracy so far: 0.9643\n",
      "[Epoch 1] Loss: 0.0017 | Accuracy so far: 0.9646\n",
      "[Epoch 1] Loss: 0.0018 | Accuracy so far: 0.9648\n",
      "[Epoch 1] Loss: 0.0007 | Accuracy so far: 0.9651\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9653\n",
      "[Epoch 1] Loss: 0.0079 | Accuracy so far: 0.9655\n",
      "[Epoch 1] Loss: 0.0313 | Accuracy so far: 0.9657\n",
      "[Epoch 1] Loss: 0.0203 | Accuracy so far: 0.9659\n",
      "[Epoch 1] Loss: 0.0042 | Accuracy so far: 0.9661\n",
      "[Epoch 1] Loss: 0.0033 | Accuracy so far: 0.9664\n",
      "[Epoch 1] Loss: 0.0017 | Accuracy so far: 0.9666\n",
      "[Epoch 1] Loss: 0.0014 | Accuracy so far: 0.9667\n",
      "[Epoch 1] Loss: 0.0070 | Accuracy so far: 0.9668\n",
      "[Epoch 1] Loss: 0.0018 | Accuracy so far: 0.9670\n",
      "[Epoch 1] Loss: 0.0025 | Accuracy so far: 0.9672\n",
      "[Epoch 1] Loss: 0.0012 | Accuracy so far: 0.9674\n",
      "[Epoch 1] Loss: 0.0007 | Accuracy so far: 0.9676\n",
      "[Epoch 1] Loss: 0.0028 | Accuracy so far: 0.9678\n",
      "[Epoch 1] Loss: 0.0018 | Accuracy so far: 0.9678\n",
      "[Epoch 1] Loss: 0.0022 | Accuracy so far: 0.9679\n",
      "[Epoch 1] Loss: 0.0027 | Accuracy so far: 0.9681\n",
      "[Epoch 1] Loss: 0.0013 | Accuracy so far: 0.9683\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9685\n",
      "[Epoch 1] Loss: 0.0011 | Accuracy so far: 0.9686\n",
      "[Epoch 1] Loss: 0.8998 | Accuracy so far: 0.9688\n",
      "[Epoch 1] Loss: 0.0032 | Accuracy so far: 0.9688\n",
      "[Epoch 1] Loss: 0.0021 | Accuracy so far: 0.9690\n",
      "[Epoch 1] Loss: 1.3127 | Accuracy so far: 0.9691\n",
      "[Epoch 1] Loss: 0.0030 | Accuracy so far: 0.9692\n",
      "[Epoch 1] Loss: 0.0029 | Accuracy so far: 0.9693\n",
      "[Epoch 1] Loss: 0.0026 | Accuracy so far: 0.9695\n",
      "[Epoch 1] Loss: 0.0022 | Accuracy so far: 0.9696\n",
      "[Epoch 1] Loss: 0.0109 | Accuracy so far: 0.9697\n",
      "[Epoch 1] Loss: 0.0047 | Accuracy so far: 0.9698\n",
      "[Epoch 1] Loss: 0.0013 | Accuracy so far: 0.9700\n",
      "[Epoch 1] Loss: 0.0016 | Accuracy so far: 0.9700\n",
      "[Epoch 1] Loss: 0.0039 | Accuracy so far: 0.9701\n",
      "[Epoch 1] Loss: 0.0022 | Accuracy so far: 0.9703\n",
      "[Epoch 1] Loss: 0.0021 | Accuracy so far: 0.9705\n",
      "[Epoch 1] Loss: 0.0013 | Accuracy so far: 0.9706\n",
      "[Epoch 1] Loss: 0.0012 | Accuracy so far: 0.9707\n",
      "[Epoch 1] Loss: 0.0010 | Accuracy so far: 0.9709\n",
      "[Epoch 1] Loss: 0.0007 | Accuracy so far: 0.9710\n",
      "[Epoch 1] Loss: 0.0205 | Accuracy so far: 0.9712\n",
      "[Epoch 1] Loss: 0.0008 | Accuracy so far: 0.9713\n",
      "[Epoch 1] Training time: 519.90 seconds\n",
      "[Epoch 1 COMPLETE] Training loss: 0.0010, Training Accuracy: 0.9713\n",
      "[Epoch 2] Loss: 0.0010 | Accuracy so far: 1.0000\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 1.0000\n",
      "[Epoch 2] Loss: 0.0011 | Accuracy so far: 1.0000\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9975\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9980\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0007 | Accuracy so far: 0.9971\n",
      "[Epoch 2] Loss: 0.0025 | Accuracy so far: 0.9975\n",
      "[Epoch 2] Loss: 0.0014 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0030 | Accuracy so far: 0.9970\n",
      "[Epoch 2] Loss: 0.0010 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0019 | Accuracy so far: 0.9958\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9954\n",
      "[Epoch 2] Loss: 0.0014 | Accuracy so far: 0.9950\n",
      "[Epoch 2] Loss: 0.0023 | Accuracy so far: 0.9947\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 0.9950\n",
      "[Epoch 2] Loss: 0.0011 | Accuracy so far: 0.9953\n",
      "[Epoch 2] Loss: 0.0043 | Accuracy so far: 0.9956\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9958\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9960\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0013 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0007 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9970\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9971\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9970\n",
      "[Epoch 2] Loss: 0.0281 | Accuracy so far: 0.9971\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.1449 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0007 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9970\n",
      "[Epoch 2] Loss: 0.0012 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0063 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.0167 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0010 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0002 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9969\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9970\n",
      "[Epoch 2] Loss: 0.0079 | Accuracy so far: 0.9971\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0039 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0111 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0205 | Accuracy so far: 0.9968\n",
      "[Epoch 2] Loss: 0.0583 | Accuracy so far: 0.9960\n",
      "[Epoch 2] Loss: 0.0131 | Accuracy so far: 0.9959\n",
      "[Epoch 2] Loss: 0.0197 | Accuracy so far: 0.9958\n",
      "[Epoch 2] Loss: 0.0030 | Accuracy so far: 0.9957\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9956\n",
      "[Epoch 2] Loss: 0.0467 | Accuracy so far: 0.9957\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9956\n",
      "[Epoch 2] Loss: 0.0026 | Accuracy so far: 0.9954\n",
      "[Epoch 2] Loss: 0.0012 | Accuracy so far: 0.9955\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9955\n",
      "[Epoch 2] Loss: 0.0018 | Accuracy so far: 0.9956\n",
      "[Epoch 2] Loss: 0.0010 | Accuracy so far: 0.9956\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9957\n",
      "[Epoch 2] Loss: 0.0014 | Accuracy so far: 0.9958\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9958\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9959\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9959\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 0.9960\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0012 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.1310 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0015 | Accuracy so far: 0.9960\n",
      "[Epoch 2] Loss: 0.0014 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9961\n",
      "[Epoch 2] Loss: 0.0229 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0002 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0002 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0068 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0015 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0012 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 1.1246 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0018 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0009 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9967\n",
      "[Epoch 2] Loss: 0.0002 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.1138 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0027 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0014 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.7053 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.8044 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0021 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0050 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0018 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0286 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0107 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0022 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.1094 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0029 | Accuracy so far: 0.9962\n",
      "[Epoch 2] Loss: 0.0007 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0010 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0013 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0019 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.5756 | Accuracy so far: 0.9963\n",
      "[Epoch 2] Loss: 0.0463 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0017 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0012 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9964\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0002 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0002 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0132 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0008 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0368 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0621 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0006 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0027 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0003 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Loss: 0.0004 | Accuracy so far: 0.9965\n",
      "[Epoch 2] Loss: 0.0005 | Accuracy so far: 0.9966\n",
      "[Epoch 2] Training time: 521.06 seconds\n",
      "[Epoch 2 COMPLETE] Training loss: 0.0002, Training Accuracy: 0.9966\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9886\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9948\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9965\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9949\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9959\n",
      "[Epoch 3] Loss: 0.0062 | Accuracy so far: 0.9966\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9971\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9975\n",
      "[Epoch 3] Loss: 0.0006 | Accuracy so far: 0.9977\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.2612 | Accuracy so far: 0.9973\n",
      "[Epoch 3] Loss: 0.0040 | Accuracy so far: 0.9975\n",
      "[Epoch 3] Loss: 0.0444 | Accuracy so far: 0.9976\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0006 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0016 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0009 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9988\n",
      "[Epoch 3] Loss: 0.0006 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0019 | Accuracy so far: 0.9977\n",
      "[Epoch 3] Loss: 0.0013 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0020 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0010 | Accuracy so far: 0.9977\n",
      "[Epoch 3] Loss: 0.0062 | Accuracy so far: 0.9977\n",
      "[Epoch 3] Loss: 0.0008 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0009 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9988\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0746 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9987\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9986\n",
      "[Epoch 3] Loss: 0.1231 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0296 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0014 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0006 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0030 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0087 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0156 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0015 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0013 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0010 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0009 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9985\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0017 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0018 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9984\n",
      "[Epoch 3] Loss: 0.1062 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.0011 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0018 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9983\n",
      "[Epoch 3] Loss: 0.1985 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0668 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0012 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0005 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9982\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0007 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0012 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0055 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0439 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0009 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0006 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0881 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0011 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9981\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0752 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0014 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9980\n",
      "[Epoch 3] Loss: 0.0021 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9979\n",
      "[Epoch 3] Loss: 0.0004 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0002 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0001 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Loss: 0.0003 | Accuracy so far: 0.9978\n",
      "[Epoch 3] Training time: 520.89 seconds\n",
      "[Epoch 3 COMPLETE] Training loss: 0.0077, Training Accuracy: 0.9978\n",
      "starting test...\n",
      "[Test Set] Evaluation time: 40.61 seconds\n",
      "\n",
      "[TEST SET] Accuracy: 0.9945 | Avg Loss: 0.0216\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForQuestionAnswering\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Dataset wrapper\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings[\"input_ids\"].size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: val[idx] for key, val in self.encodings.items()\n",
    "        }\n",
    "\n",
    "# Loaders\n",
    "train_dataset = QADataset(encodings_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataset = QADataset(encodings_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"finished loading data\")\n",
    "\n",
    "# Model\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "model.train()\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "sample_count = 0\n",
    "num_epochs = 3\n",
    "\n",
    "print(f\"starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for batch in train_loader:\n",
    "        # Move batch to GPU\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            start_positions=batch[\"start_positions\"],\n",
    "            end_positions=batch[\"end_positions\"]\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy computation\n",
    "        start_preds = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_preds = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        correct = ((start_preds == batch[\"start_positions\"]) & (end_preds == batch[\"end_positions\"])).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += batch[\"input_ids\"].size(0)\n",
    "        sample_count += batch[\"input_ids\"].size(0)\n",
    "\n",
    "        if sample_count % 100 < len(batch[\"input_ids\"]):\n",
    "            print(f\"[Epoch {epoch+1}] Loss: {loss.item():.4f} | Accuracy so far: {total_correct / total_samples:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"[Epoch {epoch+1}] Training time: {duration:.2f} seconds\")\n",
    "    epoch_acc = total_correct / total_samples\n",
    "    print(f\"[Epoch {epoch+1} COMPLETE] Training loss: {loss.item():.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "# Evaluation\n",
    "print(f\"starting test...\")\n",
    "model.eval()\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "loss_sum = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            start_positions=batch[\"start_positions\"],\n",
    "            end_positions=batch[\"end_positions\"]\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        start_preds = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_preds = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        correct = ((start_preds == batch[\"start_positions\"]) & (end_preds == batch[\"end_positions\"])).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += batch[\"input_ids\"].size(0)\n",
    "\n",
    "end_time = time.time()\n",
    "test_duration = end_time - start_time\n",
    "print(f\"[Test Set] Evaluation time: {test_duration:.2f} seconds\")\n",
    "\n",
    "test_accuracy = total_correct / total_samples\n",
    "avg_test_loss = loss_sum / len(test_loader)\n",
    "\n",
    "print(f\"\\n[TEST SET] Accuracy: {test_accuracy:.4f} | Avg Loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "Might be overfitting after the first epoch, since accuracy reached 1.0\n",
    "\n",
    "Training for three epochs with 2 A5000 GPUs and 1 CPU core.\n",
    "\n",
    "[Epoch 1] Training time: 519.90 seconds\n",
    "[Epoch 1 COMPLETE] Training loss: 0.0010, Training Accuracy: 0.9713\n",
    "\n",
    "[Epoch 2] Training time: 521.06 seconds\n",
    "[Epoch 2 COMPLETE] Training loss: 0.0002, Training Accuracy: 0.9966\n",
    "\n",
    "[Epoch 3] Training time: 520.89 seconds\n",
    "[Epoch 3 COMPLETE] Training loss: 0.0077, Training Accuracy: 0.9978\n",
    "\n",
    "[Test Set] Evaluation time: 40.61 seconds\n",
    "[TEST SET] Accuracy: 0.9945 | Avg Loss: 0.0216"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DDP\n",
    "\n",
    "Training for 3 epochs with 1 node, 4 cores, 2 workers per dataloader, and 2 A5000 GPUs\n",
    "\n",
    "[Epoch 1] Training time: 280.84s | Loss: 0.0009 | Accuracy: 0.9239\n",
    "\n",
    "[Epoch 2] Training time: 281.96s | Loss: 0.5541 | Accuracy: 0.9973\n",
    "\n",
    "[Epoch 3] Training time: 282.27s | Loss: 0.0002 | Accuracy: 0.9966\n",
    "\n",
    "[Test Set] Evaluation time: 21.24s\n",
    "[TEST SET] Accuracy: 0.9974 | Avg Loss: 0.0161"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FSDP\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Future work\n",
    "\n",
    "Train with differenet combinations of number of nodes, cores, num_workers, GPUs, type of GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
