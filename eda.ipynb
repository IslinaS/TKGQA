{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa = pd.read_csv(\"data/new_sentence_df_0509.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tuples</th>\n",
       "      <th>article_id</th>\n",
       "      <th>sentences</th>\n",
       "      <th>relation</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>merger_or_acq</th>\n",
       "      <th>keywords</th>\n",
       "      <th>mentions</th>\n",
       "      <th>relations</th>\n",
       "      <th>wikidata</th>\n",
       "      <th>...</th>\n",
       "      <th>final_company_deal</th>\n",
       "      <th>general_questions</th>\n",
       "      <th>head_questions</th>\n",
       "      <th>tail_questions</th>\n",
       "      <th>new_general_questions</th>\n",
       "      <th>new_head_questions</th>\n",
       "      <th>new_tail_questions</th>\n",
       "      <th>latest_general_questions</th>\n",
       "      <th>latest_head_questions</th>\n",
       "      <th>latest_tail_questions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>('apple_inc.', 'considering_acq', 'netflix', '...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>There is a 40% likelihood that Apple will acqu...</td>\n",
       "      <td>considering_acq</td>\n",
       "      <td>2018-01-01 09:04:47</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Citi', 'Org'), ('Apple', 'Bidder'), ('Netfl...</td>\n",
       "      <td>['40% likelihood']</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>apple_inc._netflix</td>\n",
       "      <td>((\"What's the deal between apple_inc. and netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"What's the deal between apple_inc. and netf...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>('prestige_group', 'success_acq', 'capitaland'...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NEW DELHI: Realty firm Prestige group today sa...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2018-01-01 12:46:26</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquire</td>\n",
       "      <td>[('Prestige group', 'Bidder'), ('it will acqui...</td>\n",
       "      <td>['it will acquire']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>prestige_group_capitaland</td>\n",
       "      <td>((\"What's the deal between prestige_group and ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between prestige_group and ...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>('bd_(company)', 'success_acq', 'bard', '2018-...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Under the terms of the transaction, upon compl...</td>\n",
       "      <td>success_acq</td>\n",
       "      <td>2018-01-02 00:00:00</td>\n",
       "      <td>Acq</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>[('Bard', 'Target'), ('Bard', 'Target'), ('BD'...</td>\n",
       "      <td>['upon completion of the acquisition']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>bd_(company)_bard</td>\n",
       "      <td>((\"What's the deal between bd_(company) and ba...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between bd_(company) and ba...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the bidder of the acquisition deal on...</td>\n",
       "      <td>{'before': [('Who does FlowJo LLC (Q106573956)...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>('bhi', 'success_merger', 'marcventure', '2018...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Marcventure said the merger with BHI will enab...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2018-01-02 09:09:57</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('BHI', 'Bidder'), ('Marcventure', 'Bidder'),...</td>\n",
       "      <td>['merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>bhi_marcventure</td>\n",
       "      <td>((\"What's the deal between bhi and marcventure...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"What's the deal between bhi and marcventure...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>('h.j. heinz', 'success_merger', 'kraft_foods'...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>For two years, investors and other stakeholder...</td>\n",
       "      <td>success_merger</td>\n",
       "      <td>2018-01-02 10:15:00</td>\n",
       "      <td>Merger</td>\n",
       "      <td>merger</td>\n",
       "      <td>[('Kraft Heinz', 'Org'), ('H.J. Heinz', 'Bidde...</td>\n",
       "      <td>['created through the $46 billion merger']</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>h.j. heinz_kraft_foods</td>\n",
       "      <td>((\"What's the deal between h.j. heinz and kraf...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "      <td>[(\"What's the deal between h.j. heinz and kraf...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "      <td>[(\"Who's the first bidder of the merger deal o...</td>\n",
       "      <td>{'before': [], 'after': []}</td>\n",
       "      <td>{'before': [('Who owns Kool-Aid (Q1531983) bef...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tuples  article_id  \\\n",
       "0  ('apple_inc.', 'considering_acq', 'netflix', '...         1.0   \n",
       "1  ('prestige_group', 'success_acq', 'capitaland'...         2.0   \n",
       "2  ('bd_(company)', 'success_acq', 'bard', '2018-...         5.0   \n",
       "3  ('bhi', 'success_merger', 'marcventure', '2018...        19.0   \n",
       "4  ('h.j. heinz', 'success_merger', 'kraft_foods'...        22.0   \n",
       "\n",
       "                                           sentences         relation  \\\n",
       "0  There is a 40% likelihood that Apple will acqu...  considering_acq   \n",
       "1  NEW DELHI: Realty firm Prestige group today sa...      success_acq   \n",
       "2  Under the terms of the transaction, upon compl...      success_acq   \n",
       "3  Marcventure said the merger with BHI will enab...   success_merger   \n",
       "4  For two years, investors and other stakeholder...   success_merger   \n",
       "\n",
       "           publishedAt merger_or_acq     keywords  \\\n",
       "0  2018-01-01 09:04:47           Acq      acquire   \n",
       "1  2018-01-01 12:46:26           Acq      acquire   \n",
       "2  2018-01-02 00:00:00           Acq  acquisition   \n",
       "3  2018-01-02 09:09:57        Merger       merger   \n",
       "4  2018-01-02 10:15:00        Merger       merger   \n",
       "\n",
       "                                            mentions  \\\n",
       "0  [('Citi', 'Org'), ('Apple', 'Bidder'), ('Netfl...   \n",
       "1  [('Prestige group', 'Bidder'), ('it will acqui...   \n",
       "2  [('Bard', 'Target'), ('Bard', 'Target'), ('BD'...   \n",
       "3  [('BHI', 'Bidder'), ('Marcventure', 'Bidder'),...   \n",
       "4  [('Kraft Heinz', 'Org'), ('H.J. Heinz', 'Bidde...   \n",
       "\n",
       "                                    relations  wikidata  ...  \\\n",
       "0                          ['40% likelihood']      True  ...   \n",
       "1                         ['it will acquire']     False  ...   \n",
       "2      ['upon completion of the acquisition']     False  ...   \n",
       "3                                  ['merger']     False  ...   \n",
       "4  ['created through the $46 billion merger']     False  ...   \n",
       "\n",
       "          final_company_deal  \\\n",
       "0         apple_inc._netflix   \n",
       "1  prestige_group_capitaland   \n",
       "2          bd_(company)_bard   \n",
       "3            bhi_marcventure   \n",
       "4     h.j. heinz_kraft_foods   \n",
       "\n",
       "                                   general_questions  \\\n",
       "0  ((\"What's the deal between apple_inc. and netf...   \n",
       "1  ((\"What's the deal between prestige_group and ...   \n",
       "2  ((\"What's the deal between bd_(company) and ba...   \n",
       "3  ((\"What's the deal between bhi and marcventure...   \n",
       "4  ((\"What's the deal between h.j. heinz and kraf...   \n",
       "\n",
       "                                      head_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2  {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4                        {'before': [], 'after': []}   \n",
       "\n",
       "                                      tail_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2                        {'before': [], 'after': []}   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4  {'before': [('Who owns Kool-Aid (Q1531983) bef...   \n",
       "\n",
       "                               new_general_questions  \\\n",
       "0  [(\"What's the deal between apple_inc. and netf...   \n",
       "1  [(\"What's the deal between prestige_group and ...   \n",
       "2  [(\"What's the deal between bd_(company) and ba...   \n",
       "3  [(\"What's the deal between bhi and marcventure...   \n",
       "4  [(\"What's the deal between h.j. heinz and kraf...   \n",
       "\n",
       "                                  new_head_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2  {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4                        {'before': [], 'after': []}   \n",
       "\n",
       "                                  new_tail_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2                        {'before': [], 'after': []}   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4  {'before': [('Who owns Kool-Aid (Q1531983) bef...   \n",
       "\n",
       "                            latest_general_questions  \\\n",
       "0  [(\"Who's the bidder of the acquisition deal on...   \n",
       "1  [(\"Who's the bidder of the acquisition deal on...   \n",
       "2  [(\"Who's the bidder of the acquisition deal on...   \n",
       "3  [(\"Who's the first bidder of the merger deal o...   \n",
       "4  [(\"Who's the first bidder of the merger deal o...   \n",
       "\n",
       "                               latest_head_questions  \\\n",
       "0                                                NaN   \n",
       "1                        {'before': [], 'after': []}   \n",
       "2  {'before': [('Who does FlowJo LLC (Q106573956)...   \n",
       "3                        {'before': [], 'after': []}   \n",
       "4                        {'before': [], 'after': []}   \n",
       "\n",
       "                               latest_tail_questions  \n",
       "0                                                NaN  \n",
       "1                        {'before': [], 'after': []}  \n",
       "2                        {'before': [], 'after': []}  \n",
       "3                        {'before': [], 'after': []}  \n",
       "4  {'before': [('Who owns Kool-Aid (Q1531983) bef...  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tuples', 'article_id', 'sentences', 'relation', 'publishedAt',\n",
       "       'merger_or_acq', 'keywords', 'mentions', 'relations', 'wikidata',\n",
       "       'lowered_head', 'lowered_tail', 'companies_deal', 'final_company_deal',\n",
       "       'general_questions', 'head_questions', 'tail_questions',\n",
       "       'new_general_questions', 'new_head_questions', 'new_tail_questions',\n",
       "       'latest_general_questions', 'latest_head_questions',\n",
       "       'latest_tail_questions'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest_head_questions       42.177941\n",
      "head_questions              42.177941\n",
      "tail_questions              42.177941\n",
      "latest_tail_questions       42.177941\n",
      "new_tail_questions          42.177941\n",
      "new_head_questions          42.177941\n",
      "tuples                       0.000000\n",
      "keywords                     0.000000\n",
      "merger_or_acq                0.000000\n",
      "publishedAt                  0.000000\n",
      "relation                     0.000000\n",
      "sentences                    0.000000\n",
      "article_id                   0.000000\n",
      "mentions                     0.000000\n",
      "relations                    0.000000\n",
      "general_questions            0.000000\n",
      "final_company_deal           0.000000\n",
      "companies_deal               0.000000\n",
      "lowered_tail                 0.000000\n",
      "lowered_head                 0.000000\n",
      "wikidata                     0.000000\n",
      "new_general_questions        0.000000\n",
      "latest_general_questions     0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# check null: tuples, general_questions, new_general_questions, latest_general_questions are all available\n",
    "null_percent = qa.isnull().mean().sort_values(ascending=False) * 100\n",
    "print(null_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "qa[\"general_questions\"] = qa[\"general_questions\"].apply(ast.literal_eval)\n",
    "qa[\"new_general_questions\"] = qa[\"new_general_questions\"].apply(ast.literal_eval)\n",
    "qa[\"latest_general_questions\"] = qa[\"latest_general_questions\"].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5721\n"
     ]
    }
   ],
   "source": [
    "num_rows = len(qa[\"general_questions\"])\n",
    "print(num_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_rows' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m average_lengths \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m: qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeneral_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[43mnum_rows\u001b[49m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m: qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnew_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mnum_rows,\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m: qa[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatest_general_questions\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28mlen\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39mnum_rows,\n\u001b[1;32m      5\u001b[0m }\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumber of questions: \u001b[39m\u001b[38;5;124m\"\u001b[39m, average_lengths)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_rows' is not defined"
     ]
    }
   ],
   "source": [
    "average_lengths = {\n",
    "    \"general_questions\": qa[\"general_questions\"].apply(len).sum()/num_rows,\n",
    "    \"new_general_questions\": qa[\"new_general_questions\"].apply(len).sum()/num_rows,\n",
    "    \"latest_general_questions\": qa[\"latest_general_questions\"].apply(len).sum()/num_rows,\n",
    "}\n",
    "print(f\"number of questions: \", average_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((\"What's the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'Acquisition'), (\"Who's the bidder of the acquisition deal on 2018-01-01 09:04:47?\", 'apple_inc.'), (\"Who's the target of the acquisition deal on 2018-01-01 09:04:47?\", 'netflix'), (\"What's the status of the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'considering'))\n",
      "[(\"What's the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'Acquisition', 'entity'), (\"Who's the bidder of the acquisition deal on 2018-01-01 09:04:47?\", 'apple_inc.', 'entity'), (\"Who's the target of the acquisition deal on 2018-01-01 09:04:47?\", 'netflix', 'entity'), (\"What's the status of the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'considering', 'entity')]\n",
      "[(\"Who's the bidder of the acquisition deal on 2018-01-01 09:04:47?\", 'apple_inc.', 'entity'), (\"Who's the target of the acquisition deal on 2018-01-01 09:04:47?\", 'netflix', 'entity'), (\"What's the status of the deal between apple_inc. and netflix on 2018-01-01 09:04:47?\", 'considering_acq', 'relation')]\n"
     ]
    }
   ],
   "source": [
    "first_q = qa[\"general_questions\"][0]\n",
    "print(first_q)\n",
    "first_new_q = qa[\"new_general_questions\"][0]\n",
    "print(first_new_q)\n",
    "first_latest_q = qa[\"latest_general_questions\"][0]\n",
    "print(first_latest_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')\n"
     ]
    }
   ],
   "source": [
    "first_tuple = qa[\"tuples\"][0]\n",
    "print(first_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')\n"
     ]
    }
   ],
   "source": [
    "# prepare contexts\n",
    "qa[\"tuples\"] = qa[\"tuples\"].apply(ast.literal_eval)\n",
    "print(qa[\"tuples\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "print(type(qa[\"tuples\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build context\n",
    "def transform_relation(rel):\n",
    "    if rel.endswith(\"ing_acq\"):\n",
    "        prefix = rel.replace(\"_acq\", \"\").replace(\"_\", \" \")\n",
    "        return f\"is {prefix} the acquisition of\"\n",
    "    elif rel.endswith(\"ed_acq\"):\n",
    "        prefix = rel.replace(\"_acq\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has {prefix} the acquisition of\"\n",
    "    elif rel.endswith(\"_acq\"):\n",
    "        prefix = rel.replace(\"_acq\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has achieved {prefix} of the acquisition of\"\n",
    "    elif rel.endswith(\"ing_merger\"):\n",
    "        prefix = rel.replace(\"_merger\", \"\").replace(\"_\", \" \")\n",
    "        return f\"is {prefix} the merger of\"\n",
    "    elif rel.endswith(\"ed_merger\"):\n",
    "        prefix = rel.replace(\"_merger\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has {prefix} the merger of\"\n",
    "    elif rel.endswith(\"_merger\"):\n",
    "        prefix = rel.replace(\"_merger\", \"\").replace(\"_\", \" \")\n",
    "        return f\"has achieved {prefix} of the merger of\"\n",
    "    else:\n",
    "        return rel.replace(\"_\", \" \")  # fallback: simple spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format full context string\n",
    "def format_context(tup):\n",
    "    e1, rel, e2, time = tup\n",
    "    relation_phrase = transform_relation(rel)\n",
    "    date = time.split(\" \")[0]\n",
    "    return f\"{e1} {relation_phrase} {e2} on {date}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa[\"contexts\"] = qa[\"tuples\"].apply(format_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon_(company) has achieved success of the acquisition of munster on 2019-01-10.\n"
     ]
    }
   ],
   "source": [
    "print(qa[\"contexts\"][2319])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    (What's the deal between apple_inc. and netfli...\n",
      "1    (Who's the bidder of the acquisition deal on 2...\n",
      "2    (Who's the target of the acquisition deal on 2...\n",
      "3    (What's the status of the deal between apple_i...\n",
      "Name: question_and_answer, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Explode the 'general_questions' list into separate rows\n",
    "qa_expanded = qa.explode(\"general_questions\", ignore_index=True)\n",
    "\n",
    "qa_expanded = qa_expanded.rename(columns={\"general_questions\": \"question_and_answer\"})\n",
    "\n",
    "print(qa_expanded[qa_expanded[\"tuples\"]==('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')][\"question_and_answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_expanded[[\"question\", \"answer\"]] = pd.DataFrame(qa_expanded[\"question_and_answer\"].tolist(), index=qa_expanded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    What's the deal between apple_inc. and netflix...\n",
      "1    Who's the bidder of the acquisition deal on 20...\n",
      "2    Who's the target of the acquisition deal on 20...\n",
      "3    What's the status of the deal between apple_in...\n",
      "Name: question, dtype: object\n",
      "0    Acquisition\n",
      "1     apple_inc.\n",
      "2        netflix\n",
      "3    considering\n",
      "Name: answer, dtype: object\n",
      "<class 'str'>\n",
      "<class 'str'>\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "print(qa_expanded[qa_expanded[\"tuples\"]==('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')][\"question\"])\n",
    "print(qa_expanded[qa_expanded[\"tuples\"]==('apple_inc.', 'considering_acq', 'netflix', '2018-01-01 09:04:47')][\"answer\"])\n",
    "print(type(qa_expanded[\"answer\"][0]))\n",
    "print(type(qa_expanded[\"question\"][0]))\n",
    "print(type(qa_expanded[\"contexts\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_start_char(row):\n",
    "    try:\n",
    "        contexts_lower = row[\"contexts\"].lower()\n",
    "        answer_lower = row[\"answer\"].lower()\n",
    "        return contexts_lower.index(answer_lower)\n",
    "    except ValueError:\n",
    "        return -1  # if answer not found\n",
    "\n",
    "# Apply this to your DataFrame\n",
    "qa_expanded[\"start_char\"] = qa_expanded.apply(compute_start_char, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    30\n",
      "1     0\n",
      "2    45\n",
      "3    14\n",
      "4    43\n",
      "5     0\n",
      "6    58\n",
      "7    28\n",
      "8    41\n",
      "9     0\n",
      "Name: start_char, dtype: int64\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(qa_expanded[\"start_char\"][:10])\n",
    "print((qa_expanded[\"start_char\"]==-1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/ys298/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "import torch\n",
    "from transformers import BertTokenizerFast\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def prepare_batch(batch_df):\n",
    "    questions = batch_df[\"question\"].tolist()\n",
    "    contexts = batch_df[\"contexts\"].tolist()\n",
    "    answers = batch_df[\"answer\"].tolist()\n",
    "    start_chars = batch_df[\"start_char\"].tolist()\n",
    "\n",
    "    # Tokenize as a batch\n",
    "    encodings = tokenizer(\n",
    "        questions,\n",
    "        contexts,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512,\n",
    "        return_offsets_mapping=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    # Align each answer to token-level positions\n",
    "    for i in range(len(questions)):\n",
    "        offsets = encodings[\"offset_mapping\"][i]\n",
    "        start_char = int(start_chars[i])\n",
    "        end_char = start_char + len(str(answers[i]))\n",
    "\n",
    "        start_token = end_token = 0\n",
    "        for idx, (start, end) in enumerate(offsets):\n",
    "            if start <= start_char < end:\n",
    "                start_token = idx\n",
    "            if start < end_char <= end:\n",
    "                end_token = idx\n",
    "\n",
    "        start_positions.append(start_token)\n",
    "        end_positions.append(end_token)\n",
    "\n",
    "    # Add start/end positions\n",
    "    encodings[\"start_positions\"] = torch.tensor(start_positions)\n",
    "    encodings[\"end_positions\"] = torch.tensor(end_positions)\n",
    "\n",
    "    # Remove offset mapping (no longer needed)\n",
    "    encodings.pop(\"offset_mapping\")\n",
    "\n",
    "    return encodings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(qa_expanded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings_train = prepare_batch(train_df)\n",
    "encodings_test = prepare_batch(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export encodings\n",
    "torch.save(dict(encodings_train), \"encodings_train_dict.pt\")\n",
    "torch.save(dict(encodings_test), \"encodings_test_dict.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the BERT model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try loading\n",
    "encodings_train = torch.load(\"encodings_train_dict.pt\")\n",
    "encodings_test = torch.load(\"encodings_test_dict.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['qa_outputs.bias', 'qa_outputs.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished loading data\n",
      "starting training...\n",
      "[Epoch 1] Loss: 3.0657 | Accuracy so far: 0.0769\n",
      "[Epoch 1] Loss: 2.0334 | Accuracy so far: 0.1500\n",
      "[Epoch 1] Loss: 1.2639 | Accuracy so far: 0.2138\n",
      "[Epoch 1] Loss: 1.0921 | Accuracy so far: 0.2500\n",
      "[Epoch 1] Loss: 0.7911 | Accuracy so far: 0.2956\n",
      "[Epoch 1] Loss: 0.7175 | Accuracy so far: 0.3050\n",
      "[Epoch 1] Loss: 0.5290 | Accuracy so far: 0.3310\n",
      "[Epoch 1] Loss: 0.3241 | Accuracy so far: 0.3650\n",
      "[Epoch 1] Loss: 0.4234 | Accuracy so far: 0.3949\n",
      "[Epoch 1] Loss: 0.3995 | Accuracy so far: 0.4320\n",
      "[Epoch 1] Loss: 0.3371 | Accuracy so far: 0.4647\n",
      "[Epoch 1] Loss: 0.1771 | Accuracy so far: 0.4983\n",
      "[Epoch 1] Loss: 0.0759 | Accuracy so far: 0.5337\n",
      "[Epoch 1] Loss: 0.3651 | Accuracy so far: 0.5579\n",
      "[Epoch 1] Loss: 0.3717 | Accuracy so far: 0.5811\n",
      "[Epoch 1] Loss: 0.0438 | Accuracy so far: 0.6019\n",
      "[Epoch 1] Loss: 0.3176 | Accuracy so far: 0.6191\n",
      "[Epoch 1] Loss: 0.1662 | Accuracy so far: 0.6372\n",
      "[Epoch 1] Loss: 0.6156 | Accuracy so far: 0.6523\n",
      "[Epoch 1] Loss: 0.0157 | Accuracy so far: 0.6650\n",
      "[Epoch 1] Loss: 0.0416 | Accuracy so far: 0.6787\n",
      "[Epoch 1] Loss: 0.1775 | Accuracy so far: 0.6905\n",
      "[Epoch 1] Loss: 0.4556 | Accuracy so far: 0.7010\n",
      "[Epoch 1] Loss: 0.1401 | Accuracy so far: 0.7104\n",
      "[Epoch 1] Loss: 0.0752 | Accuracy so far: 0.7200\n",
      "[Epoch 1] Loss: 0.0565 | Accuracy so far: 0.7292\n",
      "[Epoch 1] Loss: 0.0208 | Accuracy so far: 0.7396\n",
      "[Epoch 1] Loss: 0.0140 | Accuracy so far: 0.7486\n",
      "[Epoch 1] Loss: 0.0057 | Accuracy so far: 0.7576\n",
      "[Epoch 1] Loss: 0.0073 | Accuracy so far: 0.7653\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertForQuestionAnswering\n",
    "from torch.optim import AdamW\n",
    "import time\n",
    "\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.encodings[\"input_ids\"].size(0)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            key: val[idx] for key, val in self.encodings.items()\n",
    "        }\n",
    "\n",
    "train_dataset = QADataset(encodings_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_dataset = QADataset(encodings_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "print(f\"finished loading data\")\n",
    "\n",
    "model = BertForQuestionAnswering.from_pretrained(\"bert-base-uncased\")\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "model.train()\n",
    "\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "sample_count = 0\n",
    "num_epochs = 3\n",
    "\n",
    "print(f\"starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    for batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            start_positions=batch[\"start_positions\"],\n",
    "            end_positions=batch[\"end_positions\"]\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accuracy computation\n",
    "        start_preds = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_preds = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        correct = ((start_preds == batch[\"start_positions\"]) & (end_preds == batch[\"end_positions\"])).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += batch[\"input_ids\"].size(0)\n",
    "        sample_count += batch[\"input_ids\"].size(0)\n",
    "\n",
    "        # Print every 100 samples\n",
    "        if sample_count % 100 < len(batch[\"input_ids\"]):\n",
    "            print(f\"[Epoch {epoch+1}] Loss: {loss.item():.4f} | Accuracy so far: {total_correct / total_samples:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"[Epoch {epoch+1}] Training time: {duration:.2f} seconds\")\n",
    "    # Epoch summary\n",
    "    epoch_acc = total_correct / total_samples\n",
    "    print(f\"[Epoch {epoch+1} COMPLETE] Training loss: {loss.item():.4f}, Training Accuracy: {epoch_acc:.4f}\")\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "# test\n",
    "print(f\"starting test...\")\n",
    "model.eval()  # Set model to eval mode\n",
    "total_correct = 0\n",
    "total_samples = 0\n",
    "loss_sum = 0\n",
    "\n",
    "with torch.no_grad():  # Disable gradient tracking for inference\n",
    "    start_time = time.time()\n",
    "    for batch in test_loader:\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            start_positions=batch[\"start_positions\"],\n",
    "            end_positions=batch[\"end_positions\"]\n",
    "        )\n",
    "\n",
    "        # Compute loss for monitoring\n",
    "        loss = outputs.loss\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "        # Get predicted start/end positions\n",
    "        start_preds = torch.argmax(outputs.start_logits, dim=1)\n",
    "        end_preds = torch.argmax(outputs.end_logits, dim=1)\n",
    "\n",
    "        # Compute exact match accuracy\n",
    "        correct = ((start_preds == batch[\"start_positions\"]) & (end_preds == batch[\"end_positions\"])).sum().item()\n",
    "        total_correct += correct\n",
    "        total_samples += batch[\"input_ids\"].size(0)\n",
    "\n",
    "end_time = time.time()\n",
    "test_duration = end_time - start_time\n",
    "print(f\"[Test Set] Evaluation time: {test_duration:.2f} seconds\")\n",
    "# Final metrics\n",
    "test_accuracy = total_correct / total_samples\n",
    "avg_test_loss = loss_sum / len(test_loader)\n",
    "\n",
    "print(f\"\\n[TEST SET] Accuracy: {test_accuracy:.4f} | Avg Loss: {avg_test_loss:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
